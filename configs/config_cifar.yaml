base:
  cpu: False
  all_gpu: False
  gpu_index: 0


sampling:
  uvp_type: 'UVP6'          # choose 'UVP5' or 'UVP6' or 'BOTH' merge both uvp
  path_uvp5: 'D:\mojmas\files\data\UVP5_images_dataset'
  path_uvp6: 'D:\mojmas\files\data\UVP6Net'
  path_uvp6_csv: False  # load from a csv file dir i.e. 'dir' otherwise False
  path_output: 'D:\mojmas\files\data\result_sampling'
  num_class: 13             # choose 13 or 23 classes
  sampling_method: 'stratified'  # choose 'fixed' or 'uniform' or 'stratified'
  sampling_percent_uvp5: 0.9
  sampling_percent_uvp6: 0.9
  target_size: None  # default is better to set None for not loosing aspect ratio
  test_dataset_sampling: 'stratified' # choose 'fixed' or 'uniform'(percent) or 'stratified',  it created [test_percent] of dataset for testing algorithm
  test_percent_uvp5: 0.1  #for 'stratified' it should be between 0.0 and 1.0 and represent the proportion of the dataset to include in the test split.
  test_percent_uvp6: 0.1
  create_folder: False  # if True it will create sub-folders with class naming


training:
  architecture_type: 'resnet18' # choose 'resnet18', 'resnet34', 'resnet50' or 'resnext50'
  batch_size: 128
  num_workers: 10
  gray: True
  target_size: [128, 128]  #image target size
  aug_mode: 1 # 1 normal, 2 massive
  padding: True # pad image to preserve aspect ratio
  pre_train: False # True or False
  learning_rate: 0.001
  num_epoch: 2
  save_model_every_n_epoch: 50
  loss: 'cross_entropy_weight' # choose 'cross_entropy' or 'cross_entropy_weight' or 'focal' or 'LACE'
#  path_pretrain: 'D:\mojmas\files\data\result_sampling\training20231123092750' # if False training from scratch
  path_pretrain: False # if False training from scratch


training_contrastive:
  dataset: 'cifar100' # choose uvp or imagenet or inat
  im_factor: 0.01 # only for cifar dataset, choose 0.01, 0.02 or 0.1
  architecture_type: 'resnet32' # choose 'resnet18', 'resnet34', 'resnet50' or 'resnext50'
  batch_size: 5
  accumulation_steps: 1  #for mini batch size --- the training performs like batch_size // accumulation_steps i.e. 256=64*4
  num_workers: 10
  gray: True
  target_size: [32, 32]  #image target size
  padding: True # pad image to preserve aspect ratio
  pre_train: None # True or None
  learning_rate: 0.3
  momentum: 0.9 # momentum of SGD solver (default: 0.9)
  weight_decay: 0.0004 #weight decay (default: 2e-4)
  cos: True #lr decays by cosine scheduler
  schedule: [10, 20, 30, 40, 50] # learning rate schedule (when to drop lr by 10x)')
  num_epoch: 5
  warmup_epochs: 1 # warmup epochs
  loss: 'amproco' # choose 'proco' or 'amproco'
  max_modes: 5
  feat_dim: 128 # feature dimension of mlp head
  temp: 0.1  # scalar temperature for contrastive learning
  use_norm: True # cosine classifier.
#  path_pretrain: 'D:\mojmas\files\data\result_sampling\cifar-best' # if False training from scratch
  path_pretrain: False # if False training from scratch


prediction:
  path_model: 'D:\mojmas\files\data\results\uvp_training_contrastive20250113104841'
  batch_size: 2